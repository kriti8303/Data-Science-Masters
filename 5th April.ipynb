{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "812127d4-dca6-4cf6-97ce-4bda700ceaa6",
   "metadata": {},
   "source": [
    "## Question 1: Import the dataset and examine the variables. Use descriptive statistics and visualizations to understand the distribution and relationships between the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6cae29-6a98-427b-a9ab-d26b98109e62",
   "metadata": {},
   "source": [
    "To import the dataset and examine the variables, follow these steps:\n",
    "\n",
    "### 1. **Import Libraries**\n",
    "\n",
    "First, import the necessary Python libraries for data analysis and visualization.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "```\n",
    "\n",
    "### 2. **Load the Dataset**\n",
    "\n",
    "Load the dataset into a Pandas DataFrame. If the dataset is stored locally, you can use the appropriate file path.\n",
    "\n",
    "```python\n",
    "# Load the dataset\n",
    "url = 'https://drive.google.com/uc?id=1Q4J8KS1wm4-_YTuc389enPh6O-eTNcx2'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "```\n",
    "\n",
    "### 3. **Examine Descriptive Statistics**\n",
    "\n",
    "Use Pandas to get an overview of the dataset's structure and basic statistical details.\n",
    "\n",
    "```python\n",
    "# Display basic information about the dataset\n",
    "print(data.info())\n",
    "\n",
    "# Display descriptive statistics for numerical features\n",
    "print(data.describe())\n",
    "```\n",
    "\n",
    "#### **Interpretation:**\n",
    "- `info()` provides details on data types and the presence of missing values.\n",
    "- `describe()` gives the count, mean, standard deviation, min, max, and quartile values for numerical features.\n",
    "\n",
    "### 4. **Visualize the Distribution of Each Variable**\n",
    "\n",
    "#### **Histograms**\n",
    "\n",
    "Use histograms to understand the distribution of each numerical feature.\n",
    "\n",
    "```python\n",
    "# Set the style for seaborn\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Plot histograms for each feature\n",
    "data.hist(figsize=(14, 10), bins=30, edgecolor='k')\n",
    "plt.suptitle('Distribution of Features')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### **Box Plots**\n",
    "\n",
    "Box plots help identify outliers and compare distributions across different groups.\n",
    "\n",
    "```python\n",
    "# Plot box plots for each feature\n",
    "plt.figure(figsize=(14, 10))\n",
    "for i, column in enumerate(data.columns[:-1]):  # Exclude the target variable for now\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    sns.boxplot(x='Outcome', y=column, data=data)\n",
    "    plt.title(f'Box Plot of {column}')\n",
    "    plt.xlabel('Outcome')\n",
    "    plt.ylabel(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 5. **Visualize Relationships Between Variables**\n",
    "\n",
    "#### **Pair Plot**\n",
    "\n",
    "A pair plot shows pairwise relationships and distributions for each feature, colored by the outcome.\n",
    "\n",
    "```python\n",
    "# Plot pairwise relationships in the dataset\n",
    "sns.pairplot(data, hue='Outcome', palette='Set1')\n",
    "plt.suptitle('Pairwise Relationships', y=1.02)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### **Correlation Matrix**\n",
    "\n",
    "A heatmap of the correlation matrix helps identify linear relationships between numerical features.\n",
    "\n",
    "```python\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = data.corr()\n",
    "\n",
    "# Plot the heatmap of the correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Summary\n",
    "\n",
    "1. **Import and Load Data:** The dataset is loaded using Pandas and the first few rows are inspected.\n",
    "2. **Examine Descriptive Statistics:** Use `info()` and `describe()` to understand the dataset's structure and basic statistics.\n",
    "3. **Visualize Distributions:** Histograms and box plots help visualize the distribution and detect outliers.\n",
    "4. **Examine Relationships:** Pair plots and correlation matrices reveal relationships and potential multicollinearity between variables.\n",
    "\n",
    "These steps provide a comprehensive overview of the dataset, allowing you to understand the distribution of variables and relationships between them, essential for further data analysis and model building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a60f9db-5666-487d-8ea0-21dd420d6a40",
   "metadata": {},
   "source": [
    "## Question 2: Preprocess the data by cleaning missing values, removing outliers, and transforming categorical variables into dummy variables if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7104a935-a52a-4b99-909a-7336a0ba8e40",
   "metadata": {},
   "source": [
    "To preprocess the data, you need to clean missing values, handle outliers, and transform categorical variables into dummy variables. Here's a step-by-step guide:\n",
    "\n",
    "### 1. **Handling Missing Values**\n",
    "\n",
    "#### **Check for Missing Values**\n",
    "\n",
    "First, identify any missing values in the dataset.\n",
    "\n",
    "```python\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(missing_values)\n",
    "```\n",
    "\n",
    "#### **Fill or Remove Missing Values**\n",
    "\n",
    "- **Option 1: Filling Missing Values**\n",
    "  - You can fill missing values with the mean, median, mode, or a specific value.\n",
    "\n",
    "```python\n",
    "# Fill missing values with the mean\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "```\n",
    "\n",
    "- **Option 2: Removing Rows with Missing Values**\n",
    "  - You can also remove rows with missing values if they are not numerous.\n",
    "\n",
    "```python\n",
    "# Drop rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "```\n",
    "\n",
    "### 2. **Removing Outliers**\n",
    "\n",
    "#### **Identifying Outliers**\n",
    "\n",
    "Outliers can be detected using various methods, such as the Z-score or the IQR method.\n",
    "\n",
    "- **Using the IQR Method**\n",
    "\n",
    "```python\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the bounds for detecting outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out the outliers\n",
    "data_no_outliers = data[~((data < lower_bound) | (data > upper_bound)).any(axis=1)]\n",
    "```\n",
    "\n",
    "#### **Handling Outliers**\n",
    "\n",
    "- **Option 1: Remove Outliers**\n",
    "  - As shown above, remove rows that contain outliers.\n",
    "\n",
    "- **Option 2: Cap Outliers**\n",
    "  - Replace outlier values with the upper or lower bound.\n",
    "\n",
    "```python\n",
    "# Cap outliers\n",
    "data = data.clip(lower=lower_bound, upper=upper_bound, axis=1)\n",
    "```\n",
    "\n",
    "### 3. **Transforming Categorical Variables**\n",
    "\n",
    "Since the provided dataset does not contain categorical variables (all features are numerical), this step is not necessary. However, if there were categorical variables, you would convert them into dummy variables using the `pd.get_dummies()` method.\n",
    "\n",
    "```python\n",
    "# Example: Converting a categorical column to dummy variables\n",
    "# data = pd.get_dummies(data, columns=['CategoricalColumn'], drop_first=True)\n",
    "```\n",
    "\n",
    "### 4. **Normalization/Standardization**\n",
    "\n",
    "For some machine learning algorithms, it's important to normalize or standardize the data.\n",
    "\n",
    "- **Standardization (Z-score normalization):**\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the data (excluding the target variable 'Outcome')\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data.drop('Outcome', axis=1))\n",
    "data_scaled = pd.DataFrame(data_scaled, columns=data.columns[:-1])\n",
    "\n",
    "# Add the target variable back\n",
    "data_scaled['Outcome'] = data['Outcome'].values\n",
    "```\n",
    "\n",
    "- **Normalization (Min-Max scaling):**\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize the data (excluding the target variable 'Outcome')\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data.drop('Outcome', axis=1))\n",
    "data_normalized = pd.DataFrame(data_normalized, columns=data.columns[:-1])\n",
    "\n",
    "# Add the target variable back\n",
    "data_normalized['Outcome'] = data['Outcome'].values\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d7b1d2-b527-4321-8669-fedebd07201e",
   "metadata": {},
   "source": [
    "## Question 3: Split the dataset into a training set and a test set. Use a random seed to ensure reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c8e3b-c1dc-4c93-b470-c70c28bd9e2c",
   "metadata": {},
   "source": [
    "To split the dataset into training and test sets, you can use the `train_test_split` function from scikit-learn. Setting a random seed ensures that the split is reproducible, meaning you'll get the same split every time you run the code. Here's how you can do it:\n",
    "\n",
    "### 1. **Import Necessary Libraries**\n",
    "\n",
    "First, import the necessary library.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "```\n",
    "\n",
    "### 2. **Prepare the Data**\n",
    "\n",
    "Separate the features (independent variables) from the target variable (dependent variable).\n",
    "\n",
    "```python\n",
    "# Separate features and target variable\n",
    "X = data.drop('Outcome', axis=1)  # Features (all columns except 'Outcome')\n",
    "y = data['Outcome']              # Target variable ('Outcome')\n",
    "```\n",
    "\n",
    "### 3. **Split the Dataset**\n",
    "\n",
    "Use the `train_test_split` function to split the dataset. Typically, 70-80% of the data is used for training, and 20-30% is used for testing.\n",
    "\n",
    "```python\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "- `test_size=0.2`: Specifies that 20% of the data should be allocated to the test set.\n",
    "- `random_state=42`: Ensures that the split is reproducible. You can choose any integer as the seed, but using `42` is a common practice.\n",
    "\n",
    "### 4. **Verify the Split**\n",
    "\n",
    "Check the shape of the training and test sets to confirm the split.\n",
    "\n",
    "```python\n",
    "# Print the shape of the resulting datasets\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64aeef8-cc6e-474f-8f09-304d67a74171",
   "metadata": {},
   "source": [
    "## Question 4: Use a decision tree algorithm, such as ID3 or C4.5, to train a decision tree model on the training set. Use cross-validation to optimize the hyperparameters and avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8439895f-7299-42d6-a832-c5371e50c365",
   "metadata": {},
   "source": [
    "To train a decision tree model, you can use scikit-learn's implementation, which is based on the CART (Classification and Regression Trees) algorithm. However, similar principles apply when using ID3 or C4.5. Cross-validation helps to optimize hyperparameters and prevent overfitting. Here's a step-by-step guide:\n",
    "\n",
    "### 1. **Import Necessary Libraries**\n",
    "\n",
    "First, import the required libraries.\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "```\n",
    "\n",
    "### 2. **Define the Model**\n",
    "\n",
    "Create a `DecisionTreeClassifier` instance. \n",
    "\n",
    "```python\n",
    "# Initialize the Decision Tree model\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "```\n",
    "\n",
    "### 3. **Define Hyperparameters for Tuning**\n",
    "\n",
    "Define a grid of hyperparameters for cross-validation. The common hyperparameters for decision trees include `max_depth`, `min_samples_split`, `min_samples_leaf`, and `criterion`.\n",
    "\n",
    "```python\n",
    "# Define the hyperparameters grid\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "```\n",
    "\n",
    "### 4. **Use GridSearchCV for Hyperparameter Tuning**\n",
    "\n",
    "Perform a grid search with cross-validation to find the optimal hyperparameters.\n",
    "\n",
    "```python\n",
    "# Use GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(tree_model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "- `cv=5`: Specifies 5-fold cross-validation.\n",
    "- `scoring='accuracy'`: Uses accuracy as the evaluation metric.\n",
    "\n",
    "### 5. **Get the Best Model and Hyperparameters**\n",
    "\n",
    "Retrieve the best model and its hyperparameters.\n",
    "\n",
    "```python\n",
    "# Get the best parameters and estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_tree_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "```\n",
    "\n",
    "### 6. **Evaluate the Model**\n",
    "\n",
    "Evaluate the model using cross-validation on the training set to ensure it performs well.\n",
    "\n",
    "```python\n",
    "# Cross-validation score on the training set\n",
    "cv_scores = cross_val_score(best_tree_model, X_train, y_train, cv=5)\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {cv_scores.mean()}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719f27b7-173f-44e7-8d56-8101811d7d9f",
   "metadata": {},
   "source": [
    "## Question 5: Evaluate the performance of the decision tree model on the test set using metrics such as accuracy, precision, recall, and F1 score. Use confusion matrices and ROC curves to visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c82e90c-1bc7-4696-b3a2-00a4577f662c",
   "metadata": {},
   "source": [
    "To evaluate the performance of the decision tree model on the test set, you can use various metrics and visualizations, including accuracy, precision, recall, F1 score, confusion matrices, and ROC curves. Here's a step-by-step guide:\n",
    "\n",
    "### 1. **Import Necessary Libraries**\n",
    "\n",
    "First, import the required libraries.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "```\n",
    "\n",
    "### 2. **Make Predictions on the Test Set**\n",
    "\n",
    "Use the trained model to make predictions on the test set.\n",
    "\n",
    "```python\n",
    "# Predict the labels on the test set\n",
    "y_pred = best_tree_model.predict(X_test)\n",
    "y_pred_prob = best_tree_model.predict_proba(X_test)[:, 1]  # For ROC curve\n",
    "```\n",
    "\n",
    "### 3. **Calculate Evaluation Metrics**\n",
    "\n",
    "Compute the accuracy, precision, recall, and F1 score.\n",
    "\n",
    "```python\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "```\n",
    "\n",
    "### 4. **Confusion Matrix**\n",
    "\n",
    "Generate and visualize the confusion matrix.\n",
    "\n",
    "```python\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 5. **ROC Curve and AUC**\n",
    "\n",
    "Plot the ROC curve and calculate the Area Under the Curve (AUC).\n",
    "\n",
    "```python\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60ff696-4bd1-44a7-bdb1-4a9a8845268a",
   "metadata": {},
   "source": [
    "## Question 6: Interpret the decision tree by examining the splits, branches, and leaves. Identify the most important variables and their thresholds. Use domain knowledge and common sense to explain the patterns and trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85be8013-202e-4b8c-a764-19318a3eb1b1",
   "metadata": {},
   "source": [
    "To interpret a decision tree, you need to examine its structure, including the splits, branches, and leaves. The splits are determined by the features and their respective thresholds, and they segment the data into different groups. Here's how to interpret a decision tree and identify the most important variables:\n",
    "\n",
    "### 1. **Examine the Tree Structure**\n",
    "\n",
    "The structure of the decision tree can be visualized to understand the splits and how decisions are made. You can use tools like `plot_tree` from scikit-learn or more advanced tools like `Graphviz` for visualization.\n",
    "\n",
    "```python\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(best_tree_model, feature_names=X.columns, class_names=['Non-Diabetic', 'Diabetic'], filled=True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 2. **Identify the Splits and Branches**\n",
    "\n",
    "Each split in the tree is a decision point based on a feature and a threshold value. For example, a split might be based on the `Glucose` level with a threshold of 127 mg/dL. If the glucose level is greater than 127, the model predicts one class; otherwise, it predicts another.\n",
    "\n",
    "### 3. **Examine the Leaves**\n",
    "\n",
    "The leaves of the tree represent the final predictions. Each leaf node corresponds to a class label, which can be \"Non-Diabetic\" (0) or \"Diabetic\" (1). The proportion of samples in each class within a leaf can also provide insight into the model's confidence.\n",
    "\n",
    "### 4. **Determine the Feature Importance**\n",
    "\n",
    "Scikit-learn provides a way to determine the importance of each feature in making predictions. This is based on how much the feature reduces impurity across the tree.\n",
    "\n",
    "```python\n",
    "# Get feature importance\n",
    "feature_importances = best_tree_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "import pandas as pd\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(importance_df)\n",
    "```\n",
    "\n",
    "### 5. **Interpret the Results Using Domain Knowledge**\n",
    "\n",
    "- **Glucose:** A higher glucose level is a strong indicator of diabetes.\n",
    "- **BMI:** Higher BMI values are often associated with a greater risk of diabetes.\n",
    "- **Age:** Older individuals may have a higher likelihood of developing diabetes.\n",
    "- **Diabetes Pedigree Function:** A higher value indicates a stronger family history of diabetes, increasing risk.\n",
    "\n",
    "### 6. **Patterns and Trends**\n",
    "\n",
    "- **Thresholds:** The model might have learned that certain thresholds, like a glucose level above a specific value, significantly increase the probability of diabetes.\n",
    "- **Interactions:** The decision tree captures complex interactions between features, like how high glucose levels combined with a high BMI can further increase the risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da93974-31a7-4278-8c78-30586c05f181",
   "metadata": {},
   "source": [
    "## Question 7: Validate the decision tree model by applying it to new data or testing its robustness to changes in the dataset or the environment. Use sensitivity analysis and scenario testing to explore the uncertainty and risks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e0dc87-4e68-4c72-9276-398c1a62f931",
   "metadata": {},
   "source": [
    "Validating a decision tree model involves testing its performance and robustness in various scenarios, ensuring that it generalizes well to new data and can handle changes in the dataset or environment. Here are key steps to validate the decision tree model, including sensitivity analysis and scenario testing:\n",
    "\n",
    "### 1. **Apply the Model to New Data**\n",
    "\n",
    "To assess how well the model generalizes, apply it to a new, unseen dataset. This dataset should ideally be from the same population but not used during training or initial testing. If a new dataset is unavailable, a portion of the original dataset that was not used for training can serve as a substitute.\n",
    "\n",
    "```python\n",
    "# Predict on new data or a hold-out test set\n",
    "new_predictions = best_tree_model.predict(new_data)\n",
    "```\n",
    "\n",
    "### 2. **Evaluate Model Performance**\n",
    "\n",
    "Re-evaluate the model's performance metrics (accuracy, precision, recall, F1 score, etc.) on the new data to check for consistency with the initial test results.\n",
    "\n",
    "```python\n",
    "# Recalculate performance metrics on new data\n",
    "new_accuracy = accuracy_score(new_data_labels, new_predictions)\n",
    "new_precision = precision_score(new_data_labels, new_predictions)\n",
    "new_recall = recall_score(new_data_labels, new_predictions)\n",
    "new_f1 = f1_score(new_data_labels, new_predictions)\n",
    "\n",
    "print(f\"New Accuracy: {new_accuracy}\")\n",
    "print(f\"New Precision: {new_precision}\")\n",
    "print(f\"New Recall: {new_recall}\")\n",
    "print(f\"New F1 Score: {new_f1}\")\n",
    "```\n",
    "\n",
    "### 3. **Sensitivity Analysis**\n",
    "\n",
    "Sensitivity analysis involves systematically varying key input features to see how changes affect the model's output. This can reveal the model's robustness and highlight features that have a significant impact on predictions.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Example sensitivity analysis for the \"Glucose\" feature\n",
    "glucose_values = np.arange(50, 200, 10)  # Example glucose levels\n",
    "sensitivity_results = []\n",
    "\n",
    "for glucose in glucose_values:\n",
    "    temp_data = new_data.copy()\n",
    "    temp_data['Glucose'] = glucose\n",
    "    temp_predictions = best_tree_model.predict(temp_data)\n",
    "    temp_accuracy = accuracy_score(new_data_labels, temp_predictions)\n",
    "    sensitivity_results.append(temp_accuracy)\n",
    "\n",
    "# Plot sensitivity results\n",
    "plt.plot(glucose_values, sensitivity_results)\n",
    "plt.xlabel('Glucose Levels')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Sensitivity Analysis for Glucose')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 4. **Scenario Testing**\n",
    "\n",
    "Scenario testing explores how the model performs under various hypothetical situations. This can include:\n",
    "\n",
    "- **Extreme Values:** Test the model's performance on extreme or edge cases (e.g., very high or low values for certain features).\n",
    "- **Noise Injection:** Add noise to the data to test the model's robustness to noisy or imperfect data.\n",
    "- **Feature Removal:** Remove or mask certain features to understand their importance and the model's dependence on them.\n",
    "\n",
    "```python\n",
    "# Example scenario: Remove the \"BMI\" feature\n",
    "temp_data_no_bmi = new_data.drop(columns=['BMI'])\n",
    "temp_predictions_no_bmi = best_tree_model.predict(temp_data_no_bmi)\n",
    "accuracy_no_bmi = accuracy_score(new_data_labels, temp_predictions_no_bmi)\n",
    "\n",
    "print(f\"Accuracy without BMI feature: {accuracy_no_bmi}\")\n",
    "```\n",
    "\n",
    "### 5. **Exploring Uncertainty and Risks**\n",
    "\n",
    "Understanding the uncertainty and risks associated with the model's predictions is crucial. This can be done by:\n",
    "\n",
    "- **Confidence Intervals:** Calculate confidence intervals for performance metrics.\n",
    "- **Risk Assessment:** Evaluate the potential impact of incorrect predictions, especially false positives and false negatives, in a healthcare context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0776c3-e899-4368-83f3-a417621b6419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
