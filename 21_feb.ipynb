{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a7f177a-f1d9-4bdb-9861-dda56de34e72",
   "metadata": {},
   "source": [
    "## Assignment Question 1:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "778c9422-819c-47b7-bb22-54af92c58da5",
   "metadata": {},
   "source": [
    "Web scrapping is the process of using bots to extract content and data from a website. This data is usually saved in a local file so that it can be manipulated and analyzed as needed.\n",
    "\n",
    "Areas where web scrapping be used:\n",
    "1. Monitoring e-commerce prices.\n",
    "2. Finding opportunities for investment.\n",
    "3. Analyzing social media web data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b63a99-d621-4223-92a8-5b851ec914c4",
   "metadata": {},
   "source": [
    "## Assignment Question 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc35274-6688-479b-9f81-d7adf1ad1b2d",
   "metadata": {},
   "source": [
    "Methods used for web scraping:\n",
    "\n",
    "HTML Parsing: HTML Parsing involves the use of JavaScript to target a linear or nested HTML Page.\n",
    "\n",
    "DOM Parsing : The Document Object Model(DOM) defines the structure, style and content of an XML file. \n",
    "\n",
    "Vertical Aggregation : Companies that use extensive computing power can create vertical aggregation platforms to target particular verticals.\n",
    "\n",
    "XPath : XPath is short for XML Path Language for XML documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b71dc1-581c-4be9-9455-59d0a1dcbf8b",
   "metadata": {},
   "source": [
    "## Assignment Question 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e854b8c1-2f9e-4815-91b1-eb4bfdb2409e",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python package for parsing HTML and XML documents (including having malformed markup, i.e. non-closed tags, so named after tag soup). It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccdc530-ff27-4b9f-bcaf-58bf3546df80",
   "metadata": {},
   "source": [
    "## Assignment Question 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a56a56e-af7a-4e86-9703-73c2b5e09583",
   "metadata": {},
   "source": [
    "Flask is a lightweight framework to build websites. We'll use this to parse our collected data and display it as HTML in a new HTML file. The requests module allows us to send http requests to the website we want to scrap. The first line import the Flask class and the render_template method from the flask library. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa0dab5-0887-4822-9963-56f477cb756d",
   "metadata": {},
   "source": [
    "## Assignment Question 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff30408-7e86-4a43-830f-a030cbb50637",
   "metadata": {},
   "source": [
    "AWS Elastic Beanstalk AWS services used in this project.\n",
    "It is the fastest way to get web applications up and running on AWS. You can simply upload your application code, and the service automatically handles details such as resource provisioning , load balancing, auto scaling and monitoring. Elastic Beanstalk uses core AWS services such as Amazon Elastic Compute Cloud(EC2) , Amazon Elastic Container Service ( ECS), AWS Auto Scaling, and Elastic Load Balancing (ELB) to easily support applications that need to scale to server millions of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae73861-5d03-4a0a-830f-2183b7b8f034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
